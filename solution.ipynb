{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab97b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4635/4635 [06:40<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 8.867 | Val Loss: 7.411 | Val Rouge1: 0.01% | Val Rouge2: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4635/4635 [06:40<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 7.122 | Val Loss: 7.396 | Val Rouge1: 0.01% | Val Rouge2: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4635/4635 [06:41<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 7.080 | Val Loss: 7.458 | Val Rouge1: 0.01% | Val Rouge2: 0.00%\n",
      "Samples\n",
      "had a seizure in art this morning but i => am not gonna be a lot of the day i am not going to wait till (am ok now)\n",
      "so my wife starts at microsoft in the morning in the same group in an office close to => the old and i have to go to be a lot of a lot of the (mine i only have myself to blame)\n",
      "made it to st louis now waiting for the smallest plane ever to get here to take me to => the new im gonna die on the day i am not gonna be a lot of (minneapolis still in a really good mood)\n",
      "bed time something like 320 in => the morning of the new haha im gonna die on the day i am not gonna (the morning)\n",
      "is at a => bit of the morning is in the morning at all day i am not going to (wedding)\n",
      "\n",
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "100%|██████████| 148289/148289 [09:42<00:00, 254.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': np.float64(0.04496638465027878), 'rouge2': np.float64(0.0036869858757049775), 'rougeL': np.float64(0.0439967737574802), 'rougeLsum': np.float64(0.04409233013684795)}\n",
      "Samples:\n",
      "im going gokarting => in a way that you can not get.” (cool)\n",
      "going to work now getting a 5hour though first even though i have => a few days to work.\n",
      "\n",
      "Thanks to all the people who have helped (a ton of energy already)\n",
      "i miss you too and its really nice out here i dont get much cell => phone time but i had to be in the car for at least a few hours (service at the house tho lol)\n",
      "yay pens booo => ze! (work)\n",
      "goodnight goodmorning its 4am and wayyyy past bed time thankful work => well and happy day to be with you.\n",
      "\n",
      "\n",
      "-\n",
      "- (isnt until 1pm today)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lstm_model import LSTM\n",
    "from lstm_train import train\n",
    "from data_utils import TextDataset, Tokenizer, read_datafile, save_datafile, clean_string\n",
    "from eval_transformer_pipeline import eval_transformer\n",
    "\n",
    "basedir = os.path.dirname(os.getcwd())\n",
    "datadir = os.path.join(basedir, 'data')\n",
    "\n",
    "DATAFILE = os.path.join(datadir, 'raw_dataset.csv')\n",
    "#DATAFILE = os.path.join(datadir, 'raw_dataset-500k.csv')\n",
    "#DATAFILE = os.path.join(datadir, 'raw_dataset-100k.csv')\n",
    "#DATAFILE = os.path.join(datadir, 'raw_dataset-10k.csv')\n",
    "\n",
    "\n",
    "TRAIN_PART = 0.8\n",
    "VAL_PART   = 0.1\n",
    "TEST_PART  = 0.1\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    texts = [item[0] for item in batch]\n",
    "    labels = torch.tensor([item[1][0] for item in batch]).to(device)\n",
    "    lengths = torch.tensor([len(seq) for seq in texts])\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=tokenizer.pad())\n",
    "\n",
    "    return {\n",
    "        'input_ids': padded_texts,\n",
    "        'lengths': lengths,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "clean_datafile = list(filter(lambda f: len(f.split()) > 3, [clean_string(line) for line in read_datafile(DATAFILE)]))\n",
    "\n",
    "train_len = int(TRAIN_PART * len(clean_datafile))\n",
    "val_len = int(VAL_PART * len(clean_datafile))\n",
    "test_len = int(TEST_PART * len(clean_datafile))\n",
    "\n",
    "#save_datafile(re.sub('.csv', '-full.csv', DATAFILE), clean_datafile)\n",
    "#save_datafile(re.sub('.csv', '-train.csv', DATAFILE), clean_datafile[:train_len])\n",
    "#save_datafile(re.sub('.csv', '-val.csv', DATAFILE), clean_datafile[train_len:train_len+val_len])\n",
    "#save_datafile(re.sub('.csv', '-test.csv', DATAFILE), clean_datafile[train_len+val_len:])\n",
    "\n",
    "tokenizer = Tokenizer(clean_datafile)\n",
    "tokenized = [tokenizer.encode(line) for line in clean_datafile]\n",
    "\n",
    "train_dataset = TextDataset(tokenized[:train_len])\n",
    "val_dataset = TextDataset(tokenized[train_len:train_len+val_len])\n",
    "test_dataset = TextDataset(tokenized[train_len+val_len:])\n",
    "\n",
    "#BATCH_SIZE = 64\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "HIDDEN_DIM = 128\n",
    "vocab_size = tokenizer.vocab_size()\n",
    "\n",
    "print('LSTM:')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using device {device}')\n",
    "model = LSTM(vocab_size, HIDDEN_DIM, padding_idx=tokenizer.pad()).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "train(model, train_dataloader, val_dataloader, tokenizer, optimizer, criterion, rouge)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        inputs = batch['input_ids']\n",
    "        lengths = batch['lengths']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = model(inputs, lengths)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        for i in range(len(labels)):\n",
    "            input = ' '.join(tokenizer.decode(filter(lambda f: f != tokenizer.pad(), inputs[i].tolist())))\n",
    "            true_output = tokenizer.decode([labels[i].item()])[0]\n",
    "            pred_output = tokenizer.decode([preds[i].item()])[0]\n",
    "\n",
    "print('Samples')\n",
    "for i in range(5):\n",
    "    rnd = random.randrange(len(test_dataset))\n",
    "    input = test_dataset[rnd][0].tolist()\n",
    "    input_str = ' '.join(tokenizer.decode(input))\n",
    "    output = ' '.join(tokenizer.decode(model.gen_next(input, 16)))\n",
    "    reference = ' '.join(tokenizer.decode(test_dataset[rnd][1]))\n",
    "    print(f'{input_str} => {output} ({reference})')\n",
    "print()\n",
    "    \n",
    "val_datafile = read_datafile(re.sub('.csv', '-val.csv', DATAFILE))\n",
    "eval_transformer(val_datafile, rouge)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprint2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
